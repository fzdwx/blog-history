---
title: "Raft Kv"
date: 2022-10-10T22:26:55+08:00
draft: false
tags: ["mit6.824"]
---

## Introduction

这是一系列实验中的第一个，我们将构建一个`fault-tolerant key/value storage system`。在本实验中我们将实现`Raft`(一
种复制的状态机协议)。在下一个实验中，我们将在`Raft`上构建一个`key/value service`。然后，您将在多个复制的状态机上进行`shard`来提高性能。

复制的服务通过在多个复制服务器上存储其状态(即数据)的完整副本来实现`fault tolerance`。即使有一些服务器出现故障(崩溃或网络断开和抖动)`replication`也允许它们继续运行。挑战在于**failures 可能导致副本存在不同的数据**。

`Raft`将客户端的请求组织成一个序列，被成为`log`，并且确保所有`replica servers`看到相同的`log`。每个副本按照日志的顺序来执行客户端的请求，将它们应用于其本地的服务状态副本。由于**所有存活的副本读取的日志内容都是相同的，所以都以相同的顺序来执行请求，因此它们都有相同的服务状态**。如果一个服务器失败了但是后来又恢复来，`Raft`会复制把它的日志更新。只要至少大多数的服务器还或者，并且能够继续通信，那么`Raft`将继续运行。如果没有到达这个数量，那么`Raft`将会停止运行，直到到达这个数量才会重新开始。

在本lab中，你将把`Raft`实现为一个带有相关方法的GO的对象类型，目的是为了能在更大的模块中使用。一组`Raft`实例通过`RPC`来维护`replicated logs`。你的`Raft`实例将支持一连串不确定编号(数量?)的`command`，也可以叫`log entries`。这些`entries`
通过索引来进行编号。具有给定索引的`log entry`将被提交，此时，您的`Raft`应该将这个条`log`发送到更大的服务上执行。

你应该遵循 [extended Raft paper](https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf)中设计，特别是图2.你将实现论文宏的大部分内容，包括**保存持久化状态**和节**点故障自动重启后读取状态**。你将不会实现集群成员的变化(Section 6)。

你可能会发现这个 [指南](https://thesquareplanet.com/blog/students-guide-to-raft/)很有用，还有这个关于concurrency的 [锁](https://pdos.csail.mit.edu/6.824/labs/raft-locking.txt)和 [结构](https://pdos.csail.mit.edu/6.824/labs/raft-structure.txt)的建议，如果需要更广泛的视角，可以看看`axos, Chubby, Paxos Made Live, Spanner, Zookeeper, Harp, Viewstamped Replication` 和 [Bolosky et al](https://static.usenix.org/event/nsdi11/tech/full_papers/Bolosky.pdf)。

## Links

1. 项目地址: https://pdos.csail.mit.edu/6.824/labs/lab-raft.html
2. GFS 相关资料: https://fzdwx.github.io/posts/2022-10-07-gfs/#links
3. Raft paper: https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf
4. 指南: https://thesquareplanet.com/blog/students-guide-to-raft/
5. 锁: https://pdos.csail.mit.edu/6.824/labs/raft-locking.txt
6. 结构: https://pdos.csail.mit.edu/6.824/labs/raft-structure.txt
