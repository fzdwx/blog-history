<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Raft Kv | fzdwx</title><meta name=keywords content="mit6.824"><meta name=description content="Lab2文档翻译 由于我的英文不是很好，所以使用翻译软件进行翻译，然后人工进行校对进行理解。
原文地址: &nbsp;https://pdos.csail.mit.edu/6.824/labs/lab-raft.html Introduction 这是一系列实验中的第一个，我们将构建一个 fault-tolerant key/value storage system 。 在本实验中我们将实现 Raft (一种复制的状态机协议)。在下一个实验中，我们将在 Raft 上构建一个 key/value service 。 然后，您将在有多个副本的状态机上进行 shard(分片？根据 key 进行 hash 来决定路由到哪个副本上) 来提高性能。
复制(replication)通过在多个复制服务器上存储其状态(即数据)的完整副本来实现 fault tolerance 。 即使有一些服务器出现 failure (崩溃或网络断开和抖动) replication 也允许它们继续运行。 挑战在于 failures 可能导致副本存在不同的数据。
Raft 将客户端的请求组织成一个序列，被称为 log ，并且确保所有 replica servers 看到相同的 log 。 每个 replica 按照日志的顺序来执行客户端的请求，将它们应用于其本地的服务状态副本(就是运行来自客户端的命令)。 由于所有存活的副本读取的日志内容都是相同的，所以都以相同的顺序来执行请求，因此它们都有相同的服务状态。 如果一个服务器发生了 failure 但是后来又 recovery (恢复) 了，Raft 会负责将它的 log 更新到最新状态。只要至少大多数的服务器还活着，并且能够继续通信， 那么 Raft 将持续运行。如果没有到达这个数量，那么 Raft 将会停止运行，直到达到这个数量才会重新开始运行。
在本 lab 中，你将把 Raft 实现为一个带有相关方法的 GO 的对象类型，目的是为了能在更大的模块中使用。 一组 Raft 实例通过 RPC 来维护 replicated logs。你的 Raft 实例将支持一连串不确定编号的 command， 也可以叫 log entries。 这些 entity 通过 index(索引)来进行编号。具有给定索引的 log entry 将被 commit， 此时，您的 Raft 应该将这条 log 发送到 larger service 上执行。"><meta name=author content="fzdwx"><link rel=canonical href=https://fzdwx.github.io/posts/2022-10-10-raftkv/><link crossorigin=anonymous href=/assets/css/stylesheet.min.f3f498ec153460e00f4ec33403895ffff31986cc2f4db69372359388775496fd.css integrity="sha256-8/SY7BU0YOAPTsM0A4lf//MZhswvTbaTcjWTiHdUlv0=" rel="preload stylesheet" as=style><link rel=icon href=https://fzdwx.github.io/favicon.ico><link rel=apple-touch-icon href=https://fzdwx.github.io/apple-touch-icon.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-DGKZ9K6GHW"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-DGKZ9K6GHW",{anonymize_ip:!1})}</script><meta name=twitter:card content="summary"><meta name=twitter:title content="Raft Kv | fzdwx"><meta name=twitter:description content="Lab2文档翻译 由于我的英文不是很好，所以使用翻译软件进行翻译，然后人工进行校对进行理解。
原文地址: &nbsp;https://pdos.csail.mit.edu/6.824/labs/lab-raft.html Introduction 这是一系列实验中的第一个，我们将构建一个 fault-tolerant key/value storage system 。 在本实验中我们将实现 Raft (一种复制的状态机协议)。在下一个实验中，我们将在 Raft 上构建一个 key/value service 。 然后，您将在有多个副本的状态机上进行 shard(分片？根据 key 进行 hash 来决定路由到哪个副本上) 来提高性能。
复制(replication)通过在多个复制服务器上存储其状态(即数据)的完整副本来实现 fault tolerance 。 即使有一些服务器出现 failure (崩溃或网络断开和抖动) replication 也允许它们继续运行。 挑战在于 failures 可能导致副本存在不同的数据。
Raft 将客户端的请求组织成一个序列，被称为 log ，并且确保所有 replica servers 看到相同的 log 。 每个 replica 按照日志的顺序来执行客户端的请求，将它们应用于其本地的服务状态副本(就是运行来自客户端的命令)。 由于所有存活的副本读取的日志内容都是相同的，所以都以相同的顺序来执行请求，因此它们都有相同的服务状态。 如果一个服务器发生了 failure 但是后来又 recovery (恢复) 了，Raft 会负责将它的 log 更新到最新状态。只要至少大多数的服务器还活着，并且能够继续通信， 那么 Raft 将持续运行。如果没有到达这个数量，那么 Raft 将会停止运行，直到达到这个数量才会重新开始运行。
在本 lab 中，你将把 Raft 实现为一个带有相关方法的 GO 的对象类型，目的是为了能在更大的模块中使用。 一组 Raft 实例通过 RPC 来维护 replicated logs。你的 Raft 实例将支持一连串不确定编号的 command， 也可以叫 log entries。 这些 entity 通过 index(索引)来进行编号。具有给定索引的 log entry 将被 commit， 此时，您的 Raft 应该将这条 log 发送到 larger service 上执行。"><meta property="og:title" content="Raft Kv | fzdwx"><meta property="og:description" content="Lab2文档翻译 由于我的英文不是很好，所以使用翻译软件进行翻译，然后人工进行校对进行理解。
原文地址: &nbsp;https://pdos.csail.mit.edu/6.824/labs/lab-raft.html Introduction 这是一系列实验中的第一个，我们将构建一个 fault-tolerant key/value storage system 。 在本实验中我们将实现 Raft (一种复制的状态机协议)。在下一个实验中，我们将在 Raft 上构建一个 key/value service 。 然后，您将在有多个副本的状态机上进行 shard(分片？根据 key 进行 hash 来决定路由到哪个副本上) 来提高性能。
复制(replication)通过在多个复制服务器上存储其状态(即数据)的完整副本来实现 fault tolerance 。 即使有一些服务器出现 failure (崩溃或网络断开和抖动) replication 也允许它们继续运行。 挑战在于 failures 可能导致副本存在不同的数据。
Raft 将客户端的请求组织成一个序列，被称为 log ，并且确保所有 replica servers 看到相同的 log 。 每个 replica 按照日志的顺序来执行客户端的请求，将它们应用于其本地的服务状态副本(就是运行来自客户端的命令)。 由于所有存活的副本读取的日志内容都是相同的，所以都以相同的顺序来执行请求，因此它们都有相同的服务状态。 如果一个服务器发生了 failure 但是后来又 recovery (恢复) 了，Raft 会负责将它的 log 更新到最新状态。只要至少大多数的服务器还活着，并且能够继续通信， 那么 Raft 将持续运行。如果没有到达这个数量，那么 Raft 将会停止运行，直到达到这个数量才会重新开始运行。
在本 lab 中，你将把 Raft 实现为一个带有相关方法的 GO 的对象类型，目的是为了能在更大的模块中使用。 一组 Raft 实例通过 RPC 来维护 replicated logs。你的 Raft 实例将支持一连串不确定编号的 command， 也可以叫 log entries。 这些 entity 通过 index(索引)来进行编号。具有给定索引的 log entry 将被 commit， 此时，您的 Raft 应该将这条 log 发送到 larger service 上执行。"><meta property="og:type" content="article"><meta property="og:url" content="https://fzdwx.github.io/posts/2022-10-10-raftkv/"><meta property="og:image" content="https://avatars.githubusercontent.com/u/65269574?v=4"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-10T22:26:55+08:00"><meta property="article:modified_time" content="2022-10-10T22:26:55+08:00"><meta property="og:site_name" content="fzdwx"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://fzdwx.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Raft Kv","item":"https://fzdwx.github.io/posts/2022-10-10-raftkv/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Raft Kv | fzdwx","name":"Raft Kv","description":"Lab2文档翻译 由于我的英文不是很好，所以使用翻译软件进行翻译，然后人工进行校对进行理解。\n原文地址: \u0026nbsp;https://pdos.csail.mit.edu/6.824/labs/lab-raft.html Introduction 这是一系列实验中的第一个，我们将构建一个 fault-tolerant key/value storage system 。 在本实验中我们将实现 Raft (一种复制的状态机协议)。在下一个实验中，我们将在 Raft 上构建一个 key/value service 。 然后，您将在有多个副本的状态机上进行 shard(分片？根据 key 进行 hash 来决定路由到哪个副本上) 来提高性能。\n复制(replication)通过在多个复制服务器上存储其状态(即数据)的完整副本来实现 fault tolerance 。 即使有一些服务器出现 failure (崩溃或网络断开和抖动) replication 也允许它们继续运行。 挑战在于 failures 可能导致副本存在不同的数据。\nRaft 将客户端的请求组织成一个序列，被称为 log ，并且确保所有 replica servers 看到相同的 log 。 每个 replica 按照日志的顺序来执行客户端的请求，将它们应用于其本地的服务状态副本(就是运行来自客户端的命令)。 由于所有存活的副本读取的日志内容都是相同的，所以都以相同的顺序来执行请求，因此它们都有相同的服务状态。 如果一个服务器发生了 failure 但是后来又 recovery (恢复) 了，Raft 会负责将它的 log 更新到最新状态。只要至少大多数的服务器还活着，并且能够继续通信， 那么 Raft 将持续运行。如果没有到达这个数量，那么 Raft 将会停止运行，直到达到这个数量才会重新开始运行。\n在本 lab 中，你将把 Raft 实现为一个带有相关方法的 GO 的对象类型，目的是为了能在更大的模块中使用。 一组 Raft 实例通过 RPC 来维护 replicated logs。你的 Raft 实例将支持一连串不确定编号的 command， 也可以叫 log entries。 这些 entity 通过 index(索引)来进行编号。具有给定索引的 log entry 将被 commit， 此时，您的 Raft 应该将这条 log 发送到 larger service 上执行。","keywords":["mit6.824"],"wordCount":"4461","inLanguage":"en","datePublished":"2022-10-10T22:26:55+08:00","dateModified":"2022-10-10T22:26:55+08:00","author":{"@type":"Person","name":"fzdwx"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://fzdwx.github.io/posts/2022-10-10-raftkv/"},"publisher":{"@type":"Organization","name":"fzdwx","logo":{"@type":"ImageObject","url":"https://fzdwx.github.io/favicon.ico"}}}</script><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary-bg:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list-page{background:var(--theme)}.list-page:not(.dark)::-webkit-scrollbar-track{background:0 0}.list-page:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript></head><body class="type-posts kind-page layout-" id=top><script data-no-instant>function switchTheme(e){switch(e){case"light":document.body.classList.remove("dark"),document.body.classList.add("light");break;case"dark":document.body.classList.add("dark");break;default:window.matchMedia("(prefers-color-scheme: dark)").matches?document.body.classList.add("dark"):document.body.classList.add("light")}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(e){switchTheme(e),localStorage.setItem("pref-theme",e)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=e=>{setPrefTheme(e?"light":"dark")},window.addEventListener("toggle-theme",function(){const e=isDarkTheme();for(const t in toggleThemeCallbacks)toggleThemeCallbacks[t](e)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent("toggle-theme"))}</script><script>(function(){const t="auto",e=getPrefTheme(),n=e||t;switchTheme(n)})()</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=stylesheet href=/css/var.css><link rel=stylesheet href=/css/code.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lxgw-wenkai-webfont@1/style.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.11/400.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.11/400-italic.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.11/500.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.11/500-italic.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.11/700.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.11/800.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.11/700-italic.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.11/800-italic.css><div class=sticky-top><div class=header-bar></div><header class=header><nav class=nav><div class=logo><a href=https://fzdwx.github.io/ accesskey=h title="fzdwx (Alt + H)">fzdwx</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://fzdwx.github.io/notes/ title=Notes>Notes</a></li><li><a href=https://fzdwx.github.io/archives/ title=Archives>Archives</a></li><li><a href=https://fzdwx.github.io/tags/ title=Tags>Tags</a></li><li><a href=https://fzdwx.github.io/links/ title=Links>Links</a></li></ul></nav></header></div><main class="main post"><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://fzdwx.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://fzdwx.github.io/posts/>Posts</a></div><h1 class=post-title>Raft Kv</h1><div class=post-meta><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg><span>&nbsp;2022-10-10</span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon" style="user-select:text"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z" style="user-select:text"/><line x1="7" y1="7" x2="7" y2="7" style="user-select:text"/></svg>
<span class=post-tags><a href=https://fzdwx.github.io/tags/mit6.824/>mit6.824</a></span></span></div></header><div class="toc side right"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#lab2%e6%96%87%e6%a1%a3%e7%bf%bb%e8%af%91 aria-label=Lab2文档翻译>Lab2文档翻译</a><ul><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#the-code aria-label="The code">The code</a><ul><li><a href=#make aria-label=Make>Make</a></li><li><a href=#start aria-label=Start>Start</a></li></ul></li><li><a href=#2a aria-label=2A>2A</a></li></ul></li><li><a href=#raft%e8%ae%ba%e6%96%87%e7%bf%bb%e8%af%91 aria-label=Raft论文翻译>Raft论文翻译</a><ul><li><a href=#introduction-1 aria-label=Introduction>Introduction</a></li><li><a href=#replicated-state-machine aria-label="Replicated State Machine">Replicated State Machine</a></li><li><a href=#the-raft-consensus-algorithm aria-label="The Raft consensus algorithm">The Raft consensus algorithm</a><ul><li><a href=#figure-2 aria-label="Figure 2">Figure 2</a></li><li><a href=#figure-3 aria-label="Figure 3">Figure 3</a></li><li><a href=#raft-basics aria-label="Raft basics">Raft basics</a><ul><li><a href=#figure-4 aria-label="Figure 4">Figure 4</a></li><li><a href=#figure-5 aria-label="Figure 5">Figure 5</a></li></ul></li><li><a href=#leader-election aria-label="Leader election">Leader election</a></li><li><a href=#log-replication aria-label="Log replication">Log replication</a></li><li><a href=#safety aria-label=Safety>Safety</a></li></ul></li></ul></li><li><a href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0%e6%80%9d%e8%b7%af aria-label=代码实现思路>代码实现思路</a><ul><li><a href=#2a-1 aria-label=2A>2A</a></li></ul></li><li><a href=#links aria-label=Links>Links</a></li></ul></div></details></div><div class=post-content><h1 id=lab2文档翻译>Lab2文档翻译<a hidden class=anchor aria-hidden=true href=#lab2文档翻译>¶</a></h1><p>由于我的英文不是很好，所以使用翻译软件进行翻译，然后人工进行校对进行理解。</p><p>原文地址: &nbsp;<a href=https://pdos.csail.mit.edu/6.824/labs/lab-raft.html target=_blank rel=noopener>https://pdos.csail.mit.edu/6.824/labs/lab-raft.html</a></p><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>¶</a></h2><p>这是一系列实验中的第一个，我们将构建一个 <em>fault-tolerant key/value storage system</em> 。
在本实验中我们将实现 <em>Raft (一种复制的状态机协议)</em>。在下一个实验中，我们将在 Raft 上构建一个 key/value service 。
然后，您将在有多个副本的状态机上进行 shard(分片？根据 key 进行 hash 来决定路由到哪个副本上) 来提高性能。</p><p>复制(replication)通过在多个复制服务器上存储其状态(即数据)的完整副本来实现 <em>fault tolerance</em> 。
即使有一些服务器出现 failure (崩溃或网络断开和抖动) replication 也允许它们继续运行。 挑战在于 failures 可能导致副本存在不同的数据。</p><p>Raft 将客户端的请求组织成一个序列，被称为 log ，并且确保所有 replica servers 看到相同的 log 。
每个 replica 按照日志的顺序来执行客户端的请求，将它们应用于其本地的服务状态副本(就是运行来自客户端的命令)。
由于所有存活的副本读取的日志内容都是相同的，所以都以相同的顺序来执行请求，因此它们都有相同的服务状态。
如果一个服务器发生了 failure 但是后来又 recovery (恢复) 了，Raft 会负责将它的 log 更新到最新状态。只要至少大多数的服务器还活着，并且能够继续通信，
那么 Raft 将持续运行。如果没有到达这个数量，那么 Raft 将会停止运行，直到达到这个数量才会重新开始运行。</p><p>在本 lab 中，你将把 Raft 实现为一个带有相关方法的 GO 的对象类型，目的是为了能在更大的模块中使用。
一组 Raft 实例通过 RPC 来维护 replicated logs。你的 Raft 实例将支持一连串不确定编号的 command，
也可以叫 log entries。 这些 entity 通过 index(索引)来进行编号。具有给定索引的 log entry 将被 commit，
此时，您的 Raft 应该将这条 log 发送到 larger service 上执行。</p><p>你应该遵循&nbsp;<a href=https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf target=_blank rel=noopener>extended Raft paper</a>
中设计，
特别是&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-2>图2</a>
.你将实现论文中的大部分内容，包括保存持久化状态和节点故障自动重启后读取状态。
你将不会实现集群成员的变化(Section 6)。</p><p>你可能会发现这个&nbsp;<a href=https://thesquareplanet.com/blog/students-guide-to-raft/ target=_blank rel=noopener>指南</a>
很有用，
还有这个关于concurrency的&nbsp;<a href=https://pdos.csail.mit.edu/6.824/labs/raft-locking.txt target=_blank rel=noopener>锁</a>
和&nbsp;<a href=https://pdos.csail.mit.edu/6.824/labs/raft-structure.txt target=_blank rel=noopener>结构</a>
的建议，
如果需要更广泛的视角，可以看看 Paxos,Chubby,Paxos Made Live,Spanner,Zookeeper,Harp,Viewstamped Replication
和&nbsp;<a href=https://static.usenix.org/event/nsdi11/tech/full_papers/Bolosky.pdf target=_blank rel=noopener>Bolosky et al</a>
。</p><p>请记住，本 lab 中最具挑战性的部分可能不是实现你的解决方案，而是调试它。为了帮助应对这一挑战，你可能需要把事件花在如何使你的实现更容易调试。
你可以参考&nbsp;<a href=https://pdos.csail.mit.edu/6.824/labs/guidance.html target=_blank rel=noopener>指导页</a>
和这篇关于有效打印声明的&nbsp;<a href=https://blog.josejg.com/debugging-pretty/ target=_blank rel=noopener>博文</a>
。</p><p>我们还提供了&nbsp;<a href=https://pdos.csail.mit.edu/6.824/notes/raft_diagram.pdf target=_blank rel=noopener>Raft 交互图</a>
，
可以帮助阐明Raft代码如何与上层(使用者?)交互。</p><h2 id=the-code>The code<a hidden class=anchor aria-hidden=true href=#the-code>¶</a></h2><p>通过向<code>raft/raft.go</code>添加代码来实现Raft。在该文件中，你会发现骨架代码，以及如何发送和接收 RPC 的例子。
你的实现必须支持以下接口，测试者和(最终)你的 key/value service 将使用该接口。你可以在<code>raft.go</code>的注释中找到更多细节。</p><div class="tip custom-block"><p class=custom-block-title>TIP</p><p>Raft 实例只能通过 rpc 进行通信且必须使用<code>labrpc</code>这个包(例如不能使用文件以及共享变量)。</p></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=c1>// create a new Raft server instance:
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nx>rf</span> <span class=o>:=</span> <span class=nf>Make</span><span class=p>(</span><span class=nx>peers</span><span class=p>,</span> <span class=nx>me</span><span class=p>,</span> <span class=nx>persister</span><span class=p>,</span> <span class=nx>applyCh</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// start agreement on a new log entry:
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nx>rf</span><span class=p>.</span><span class=nf>Start</span><span class=p>(</span><span class=nx>command</span> <span class=kd>interface</span><span class=p>{})</span> <span class=p>(</span><span class=nx>index</span><span class=p>,</span> <span class=nx>term</span><span class=p>,</span> <span class=nx>isleader</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// ask a Raft for its current term, and whether it thinks it is leader
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nx>rf</span><span class=p>.</span><span class=nf>GetState</span><span class=p>()</span> <span class=p>(</span><span class=nx>term</span><span class=p>,</span> <span class=nx>isLeader</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// each time a new entry is committed to the log, each Raft peer
</span></span></span><span class=line><span class=cl><span class=c1>// should send an ApplyMsg to the service (or tester).
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kd>type</span> <span class=nx>ApplyMsg</span>
</span></span></code></pre></div><h3 id=make>Make<a hidden class=anchor aria-hidden=true href=#make>¶</a></h3><blockquote><p>Make(peers []*labrpc.ClientEnd, me int,persister *Persister, applyCh chan ApplyMsg)</p></blockquote><p>用于创建 Raft server。</p><ol><li>所有的 raft server 的端口都在<code>peers[]</code>存放(包括当前的服务)，当前服务的端口可以通过<code>peers[me]</code>来获取。</li><li>所有的服务的<code>perrs[]</code>数组都具有相同的顺序。</li><li><code>presister</code>是一个用来存放<code>persistent state</code>的地方，并且在初始的时候会保存最具的状态，如果有。</li><li><code>applyCh</code>是 service 或 tester 发送消息给 raft 的通道。<code>Make()</code>
必须快速返回，所以它应该为一些长时间运行的任务启动<code>goruntines</code>。</li></ol><h3 id=start>Start<a hidden class=anchor aria-hidden=true href=#start>¶</a></h3><p>使用 Raft 的服务（例如 kv 服务器）希望就下一个要附加到 Raft 日志的命令开始协议。如果此服务器不是领导者，则返回
false。否则启动协议并立即返回。无法保证此命令将永远提交到 Raft 日志，因为领导者可能会失败或失去选举。即使 Raft
实例被杀死，这个函数也应该优雅地返回。第一个返回值是该命令在提交时将出现的索引。第二个返回值是当前术语。如果此服务器认为它是领导者，则第三个返回值为
true。</p><blockquote><p>Start(command interface{}) (int, int, bool)</p></blockquote><p>使用 Raft 的服务(e.g k/v server)希望就下一个要追加到 Raft 日志的命令开始协议。
如果当前 Raft server 不是 leader 则返回<code>false</code>。否则启动协议并立即返回，无需等待日志追加完成。
所以无法保证此命令将一定会被提交到 Raft 日志中，因为 leader 可能会失败或者在输掉选举。
即使 Raft 实例被 kill 这个函数也应该 return gracefully(优雅返回)。</p><p>第一个返回值是该命令在 commit 时将被设置的 index。第二个返回值是当前的 term(任期)。如果此服务器认为自己是 leader
则第三个返回值是<code>true</code>。</p><p>每个新提交的<code>Raft log entity</code>都应该发送一个<code>AppliMsg</code>到<code>Make()</code>的<code>applyCh</code>中。</p><h2 id=2a>2A<a hidden class=anchor aria-hidden=true href=#2a>¶</a></h2><p>实现 Raft leader election 以及 heartbeats(<code>AppendEntries RPCs</code>中不附带 log entries)。</p><p>2A的目标是: 选出一个 leader，如果没有 failure，它仍然是 leader，如果 old leader 失败或者与 old leader 之间的数据包发生丢失则由
new
leader 接管。</p><div class="tip custom-block"><p class=custom-block-title>TIP</p><p>这个失败是 leader 出现故障的意思？就是说只要它没出现运行故障或者网络问题就永远是leader？</p></div><p>要点:</p><ol><li>通过运行<code>go test -run 2A</code>来进行测试你的实现。</li><li>按照论文的&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-2>图2</a>
，主要关心发送和接收<code>RequestVote RPCs</code>
，与<code>the Rules for Servers that relate to elections</code>
以及<code>the State related to leader election</code>。</li><li>添加&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-2>图2</a>
中与 leader election 相关的状态到<code>Raft</code>这个结构体中，且还需要定义一个结构来保存每个日志的信息。</li><li>实现<code>RequestVote()</code>，这样 raft 服务们就能互相投票了。添加<code>RequestVOteArgs</code>和<code>RequestVoteReply</code>者两个结构体。修改<code>Make()</code>
，创建一个 goroutine，用于检查心跳消息，如果有一段时间没有收到 peer 的消息时将发送<code>RequestVote RPCs</code>来定期发起领导者选举。这样，如果有
leader 了，peer 将知道谁是 leader，或者自己成为 leader。</li><li>实现心跳，需要定义一个<code>AppendEntries RPC</code>结构(尽管你可能还不需要所有参数)，
并且让 leader 定期发送它。编写一个<code>AppendEntries RPC</code>的 handle method，用于重置选举超时，
这样当有一个人已经当选时，其他服务器不会又成为 leader。</li><li>确保不同 peer 的选举超时不在同一时间发生，否则所有peer将只为自己投票，这样就没有人会成为leader了。</li><li>在测试时，leader 每秒发送的RPC请求不能超过 10 次。</li><li>在测试时，要求 Raft 在 old leader 失败后5秒内选举 new leader(如果大多数节点仍然能继续通讯)。
但是请记住，如果出现<code>split vote</code>(如果数据包丢失或者候选人选择了相同的随机退避时间就有可能发生)，leader 选举可能需要多轮。
所以必须设置足够短的选举超时(也就是心跳间隔)，即使会选举多轮，也有可能在5秒内完成。</li><li>论文的&nbsp;<a href=/posts/2022-10-10-raftkv/#leader-election>Leader election</a>
这一节中提到的选举超时范围是150到300毫秒。
只有当 leader 发送心跳的频率大大高于150毫秒一次时，上面提到的范围才有意义。由于在测试时限制每秒10次心跳，
所以必须使用比论文中更大的选举超时时间，但是不能太大，因为可能会无法在5秒内完成选举。</li><li>如果您的代码无法通过测试，请再次阅读论文中的&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-2>图2</a>
，leader 选举的全部逻辑分布在图中多个部分。</li><li>不要忘记实现<code>GetState()</code>。</li><li>在测试时，如果要关闭一个raft实例，会调用<code>rf.kill()</code>。我们可以调用<code>rf.killed</code>来检查是否被调用了<code>kill()</code>。您可能希望在所有的循环中都这样
做，以避免死亡的Raft实例打印混乱的信息。</li><li><code>go RPC</code>只发送名称以大写字母开头的结构体字段。子结构体也必须拥有大写的字段名。</li></ol><h1 id=raft论文翻译>Raft论文翻译<a hidden class=anchor aria-hidden=true href=#raft论文翻译>¶</a></h1><blockquote><p>选取一些重要的片段进行翻译</p></blockquote><p>原文地址: &nbsp;<a href=https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf target=_blank rel=noopener>https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf</a></p><h2 id=introduction-1>Introduction<a hidden class=anchor aria-hidden=true href=#introduction-1>¶</a></h2><p>Raft 算法和已经存在的共识算法在某些地方很相似(主要是 Oki 以及 Liskov&rsquo;s Viewstamped Replication)，但是它有以下新特性:</p><details class="details custom-block"><summary>原文</summary>
raft is similar in many ways to existing consensus algorithms (most notably, Oki and Liskov’s Viewstamped
Replication), but it has several novel features:</details><ul><li>强领导者: Raft 使用一种比其他共识算法更强的领导形式。例如，日志只从 leader 发送给其他服务器。这简化了对复制日志的管理，使的
Raft 更容易理解。</li><li>领导选举: Raft 使用随机的计时器来选取 leader。这种方式仅仅是在所有共识算法都需要改进的心跳机制上有些许改进，然而这使得
Raft 在解决冲突时更简单和快速。</li><li>成员调整: 集群中更改 server 时，Raft 使用了新的联合共识(join consensus)算法，
两种不同的配置的majorities在变更期间重叠(overlap)， 允许集群在配置变更的时候，持续正常运行。</li></ul><details class="details custom-block"><summary>原文</summary><ul><li>Strong leader: Raft uses a stronger form of leadership than other consensus algorithms. For example,log entries
only flow from the leader to other servers. This simplifies the management of the replicated log and makes Raft
easier to understand.</li><li>Leader election: Raft uses randomized timers to elect leaders. This adds only a small amount of mechanism to the
heartbeats already required for any consensus algorithm, while resolving conflicts simply and rapidly.</li><li>Membership changes: Raft’s mechanism for changing the set of servers in the cluster uses a new joint consensus
approach where the majorities of two different configurations overlap during transitions. This allows the cluster
to continue operating normally during configuration changes.</li></ul></details><h2 id=replicated-state-machine>Replicated State Machine<a hidden class=anchor aria-hidden=true href=#replicated-state-machine>¶</a></h2><p><code>复制状态机(Replicated State Machine)</code>在分布式系统中被用于解决各种容错问题。例如GFS,HDFS,RAMCloud等单leader的大型集群系统，通常使用独立
的复制状态机来管理领导选举和存储配置信息来保证在leader崩溃会存活下来，复制状态机的例子包括Chubby以及Zookeeper。</p><p><figure id=a-/images/7.png class=align-center><img src=/images/7.png alt="Figure 1: 复制状态机架构。共识算法管理来自客户端的包含状态机命令的复制日志，状态机按照相同的顺序来处理它们，所以它们产生相同的输出。"><figcaption>Figure 1: 复制状态机架构。共识算法管理来自客户端的包含状态机命令的复制日志，状态机按照相同的顺序来处理它们，所以它们产生相同的输出。</figcaption></figure></p><p>共识算法通常出现在复制状态机的上下文中，在这种方法中，在一组server上的状态机对同一个的状态会计算出相同的副本，即使一些server宕机也可以继续运行。</p><details class="details custom-block"><summary>原文</summary>
Replicated state machines are used to solve a variety of fault tolerance problems in distributed systems. For example,
large-scale systems that have a single cluster leader, such as GFS, HDFS, and RAMCloud, typically use a separate
replicated state machine to manage leader election and store configuration information that must survive leader
crashes. Examples of replicated state machines include Chubby and ZooKeeper. Consensus algorithms typically arise in
the context of replicated state machines.In this approach, state machines on a collection of servers compute identical
copies of the same state and can continue operating even if some of the servers are down.</details><p>复制状态机通过<strong>复制日志实现</strong>，如图一所示。每个服务保存包含一系列命令的日志，其状态机按照顺序来执行它们。
每个<strong>日志包含相同顺序的相同命令</strong>，所以每个状态机处理相同的命令序列。因为<strong>状态机是确定的</strong>，
所以每个状态机<strong>会计算出相同的状态</strong>和<strong>相同顺序的输出</strong>。</p><details class="details custom-block"><summary>原文</summary>
Replicated state machines are typically implemented using a replicated log, as shown in Figure 1. Each server stores a
log containing a series of commands, which its state machine executes in order. Each log contains the same commands in
the same order, so each state machine processes the same sequence of commands. Since the state machines are
deterministic, each computes the same state and the same sequence of outputs.</details><p>共识算法的任务是<strong>保证复制日志的一致性</strong>。服务器上的共识模块接收来自客户端的命令并把它们添加到日志中，
并与其他服务器上的共识模块进行通讯以确保它们的每一条日志最终都相同(相同的请求有相同的顺序)， 即使有一些服务失败了。一旦命令被正确的复制，
每一个服务的状态机会按照日志的顺序去处理它们，然后将结果返回给客户端。</p><p>因此，这些服务似乎成为了一个单一的，高度可靠的状态机。</p><details class="details custom-block"><summary>原文</summary>
Keeping the replicated log consistent is the job of the consensus algorithm. The consensus module on a server receives
commands from clients and adds them to its log. It communicates with the consensus modules on other servers to ensure
that every log eventually contains the same requests in the same order, even if some servers fail. Once commands are
properly replicated, each server’s state machine processes them in log order, and the outputs are returned to clients.
As a result, the servers appear to form a single, highly reliable state machine.</details><p>在实际的共识算法通常有以下属性:</p><ul><li>确保非拜占庭(non-Byzantine)条件下的<em>安全性</em>(永远不返回错误的结果)，包括网络延迟，分区以及网络数据包丢失、冗余、乱序。</li><li>只要大多数的服务都在运行并能相互通信且和客户端通信，它们就能发挥出全部的功能(<em>可用性</em>)。因此，一个5台服务的集群能容忍2台服务出现故障。
假定服务应为停机而出现故障，它们可能稍后会从stable storage`中恢复状态并从新加入集群。</li><li>不依赖与timing来保证日志的一致性: 错误的时钟和极端的信息延迟延迟在最坏的情况下会导致可用性问题。</li><li>在一般情况下，一个命令的完成在于集群中的大多数对单轮远程调用作出响应，少数低水平的服务不会影响系统的整体性能。</li></ul><details class="details custom-block"><summary>原文</summary><p>Consensus algorithms for practical systems typically have the following properties:</p><ul><li>They ensure <em>safety</em> (never returning an incorrect result) under all non-Byzantine conditions,
including network delays, partitions, and packet loss, duplication, and reordering.</li><li>They are fully functional (<em>available</em>) as long as any
majority of the servers are operational and can communicate with each other and with clients. Thus, a
typical cluster of five servers can tolerate the failure of any two servers. Servers are assumed to fail by
stopping; they may later recover from state on stable storage and rejoin the cluster.</li><li>They do not depend on timing to ensure the consistency of the logs: faulty clocks and extreme message
delays can, at worst, cause availability problems.</li><li>In the common case, a command can complete as soon as a majority of the cluster has responded to a single round of
remote procedure calls; a minority of low servers need not impact overall system performance.</li></ul></details><h2 id=the-raft-consensus-algorithm>The Raft consensus algorithm<a hidden class=anchor aria-hidden=true href=#the-raft-consensus-algorithm>¶</a></h2><p>Raft就是用于管理上一解描述的复制日志的算法。&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-2>图2</a>
是对该算法的精简型式的总结，&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-3>图3</a>
列出来该算法的关键属性，接下来对这些部分进行逐一讨论。</p><details class="details custom-block"><summary>原文</summary>
Raft is an algorithm for managing a replicated log of the form described in Section 2. Figure 2 summarizes the
algorithm in condensed form for reference, and Figure 3 lists key properties of the algorithm; the elements of these
figures are discussed piecewise over the rest of this section.</details><p>Raft首先通过选举出一位 <em>leader</em> 来实现共识，然后由leader完全管理日志复制。leader接收来自客户端的日志，然后复制给其他服务，并且通知在何时
它们可以安全的消费(作用到状态机上)这些日志。leader简化了日志复制的管理。例如: leader可以自主确定新日志存放在哪个位置而不用询问其他服务，
数据以一种简单的方式从leader流向其他服务。leader可以失败以及断开连接，这个时候需要重新选举leader。</p><details class="details custom-block"><summary>原文</summary>
Raft implements consensus by first electing a distinguished leader, then giving the leader complete responsibility for
managing the replicated log. The leader accepts log entries from clients, replicates them on other servers, and tells
servers when it is safe to apply log entries to their state machines. Having a leader simplifies the management of the
replicated log. For example, the leader can decide where to place new entries in the log without consulting other
servers, and data flows in a simple fashion from the leader to other servers. A leader can fail or become disconnected
from the other servers, in which case a new leader is elected.</details><p>基于leader的方法，Raft将一致性问题为了三个子过程来解决:</p><ul><li>leader选举: 当leader失败(宕机)时需要选举新leader</li><li>日志复制: leader接收来自客户端的日志，并复制给集群中的其他机器，强制其他服务器与自己的一致</li><li>安全: Raft的安全就在于&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-3>图3</a>
中的安全属性: 如果任何服务器消费了一个日志，那么其他任何服务器就不
能在相同的日志索引消费不同的日志</li></ul><details class="details custom-block"><summary>原文</summary><p>Given the leader approach, Raft decomposes the consensus problem into three relatively independent subproblems, which
are discussed in the subsections that follow:</p><ul><li>Leader election: a new leader must be chosen when an existing leader fails</li><li>Log replication: the leader must accept log entries from clients and replicate them across the cluster,
forcing the other logs to agree with its own</li><li>Safety: the key safety property for Raft is the State Machine Safety Property in Figure 3: if any server has applied
a particular log entry to its state machine, then no other server may apply a different command for the same log
index. Section 5.4 describes how Raft ensures this property; the solution involves an additional restriction on the
election mechanism described in Section 5.2.</li></ul></details><h3 id=figure-2>Figure 2<a hidden class=anchor aria-hidden=true href=#figure-2>¶</a></h3><p><figure id=a-/images/raftp2.png class=align-center><img src=/images/raftp2.png alt="Figure 2: Raft共识算法的精简摘要(不包括成员更改以及日志压缩)。左上角的服务器行为被描述为一组独立且重复触发的规则。"><figcaption>Figure 2: Raft共识算法的精简摘要(不包括成员更改以及日志压缩)。左上角的服务器行为被描述为一组独立且重复触发的规则。</figcaption></figure></p><p><strong>state</strong>:</p><ul><li>在所有服务器上持久化(在响应RPCs之前进行更新)<ul><li><code>currentTerm</code>: 服务器知道的最后的任期号(初始0，单调递增)</li><li><code>votedFor</code>: 当前服务器投给哪个服务器？</li><li><code>log[]</code>: 日志，包含要执行的命令以及收到该日志的时间。</li></ul></li><li>在所有服务器上不稳定存在<ul><li><code>commitIndex</code>: 已知的提交的日志中的最大索引(初始0，单调递增)</li><li><code>lastApplied</code>: 状态机执行的日志中的最大索引(初始0，单调递增)</li></ul></li><li>在leader上不稳定存在(在每次重新选举后初始化)<ul><li><code>nextIndex[]</code>: 对于每一个服务器，记录需要发给它的下一个日志条目的索引(初始为leader的最后一条日志索引+1)</li><li><code>matchIndex[]</code>: 对于每一个服务器，记录已经复制到该服务器的日志的最高索引值(初始0，单调递增)</li></ul></li></ul><p><strong>AppendEntries RPC</strong></p><blockquote><p>由leader发起调用来复制日志，同时也用于心跳检测</p></blockquote><ul><li>Arguments:<ul><li><code>term</code>: leader的任期</li><li><code>leaderId</code>: 用于follower找到leader</li><li><code>prevLogIndex</code>: 前一个日志的索引</li><li><code>prevLogTerm</code>: 前一个日志的<code>term</code></li><li><code>entries[]</code>: 用于存放日志(为空时是心跳检测，可能一次会发送多条来提升效率)</li><li><code>leaderCommit</code>: leader的<code>commitIndex</code></li></ul></li><li>Results:<ul><li><code>term</code>: <code>currentTerm</code>，用于leader更新自己的<code>term</code></li><li><code>success</code>: 如果follower的<code>pervLogIndex</code>以及<code>prevLogTerm</code>能够匹配上则为true</li></ul></li><li>Receiver implementation:<ul><li><code>if term &lt; currentTerm then return false</code>(如果 term &lt; currentTerm返回 false)</li><li><code>if log[prevLogIndex].term != prevLogTerm then return false</code>(如果在prevLogIndex处的日志的任期号与prevLogTerm不匹配时，返回
false)</li><li><code>if log[oldIndex].term != log[newIndex].term then remove log[oldIndex,lastIndex]</code>(
如果一个已经存在的日志与新的日志冲突(<em><code>index</code>相同但是<code>term</code>不同</em>)，则删除该索引处以及之后的所有日志)</li><li>添加在日志列表中不存在的新日志</li><li><code>if leaderCommit > commitIndex then commitIndex = min(leaderCommit,log[].last.commitIndex)</code>(如果leaderCommit >
commitIndex，将commitIndex设置为leaderCommit和最新日志条目索引号中较小的一个)</li></ul></li></ul><p><strong>RequestVote RPC</strong></p><blockquote><p>候选人调用，收集选票</p></blockquote><ul><li>Arguments:<ul><li><code>term</code>: candidate的任期号</li><li><code>candidateId</code>: 发起请求的candidate的id</li><li><code>lastLogIndex</code>: candidate的最后一条日志的索引</li><li><code>lastLogTerm</code>: candidate最后一条日志对应的任期号</li></ul></li><li>Results:<ul><li>term: <code>currentTerm</code>，用于candidate更新自己的<code>term</code></li><li>voteGranted: true表示候选人获得了选票</li></ul></li><li>Receiver implementation:<ul><li><code>if term &lt; currentTerm then return false</code>(如果term &lt; currentTerm返回 false)</li><li><code>if (votedFor is null or votedFor == candidateId) and (lastLogIndex,lastLogTerm) == log[].last then return true</code>
(如果votedFor为空或者与candidateId相同，并且候选人的日志和自己的日志一样新，则给该候选人投票)</li></ul></li></ul><p><strong>Rules for Servers</strong></p><ul><li>All Servers:<ul><li><code>if commitIndex > lastApplied then incr lastApplied and exec log[lastApplied]</code>（如果commitIndex >
lastApplied，lastApplied自增，将log[lastApplied]应用到状态机）</li><li><code>if appendEntries.logs exist (log.term > currentTerm) then currentTerm = log.term and set status = follower</code>(如果
RPC 的请求或者响应中包含一个 term T 大于 currentTerm，则currentTerm赋值为 T，并切换状态为追随者follower)</li></ul></li><li>Followers:<ul><li>不会发出任何请求，只会对来自candidates以及leader的请求做出响应</li><li>选举超时后，如果未收到当前leader的<code>AppendEntries RPC</code>或没有收到其他candidates的投票请求:则转换为candidate</li></ul></li><li>Candidates:<ul><li>转换成candidate之后开始选举<ul><li>incr <code>currentTerm</code></li><li>投票给自己</li><li>reset election timer</li><li>发送<code>RequestVote RPC</code>给其他所有服务器</li></ul></li><li>如果收到了多数的选票则成为leader</li><li>如果收到 new leader 的<code>AppendEntries RPC</code>则成为 follower</li><li>如果选举超时则开始新一轮的选举</li></ul></li><li>Leaders:<ul><li>选举时: 向其他服务器发送空的<code>AppendEntries RPC</code>，在空闲时重复发送以防止选举超时</li><li>如果收到来自客户端的命令: 添加到本地日志，在执行并作用到状态机后作出响应</li><li>对于follower<code>if last log index >= nextIndex</code>(如果上一次收到的日志的索引大于这次要发送给它的日志的索引(
nextIndex)):
则通过<code>AppendEntries RPC</code>将nextIndex之后的所有日志都发送发送出去<ul><li>如果成功: 将该follower的<code>nextIndex</code>以及<code>matchIndex</code>更新</li><li>如果因为日志不一致导致失败: <code>nextIndex</code>递减并重新发送</li></ul></li><li>如果存在一个数N，满足<code>N > commitIndex</code>，大多数的<code>matchIndex[i] >= N</code>
以及<code>log[N].term == currentTerm</code>: <code>set commitIndex = N</code></li></ul></li></ul><h3 id=figure-3>Figure 3<a hidden class=anchor aria-hidden=true href=#figure-3>¶</a></h3><p><figure id=a-/images/f3.png class=align-center><img src=/images/f3.png alt="Figure 3: Raft保证这些属性在在任何时候都上正确的。"><figcaption>Figure 3: Raft保证这些属性在在任何时候都上正确的。</figcaption></figure></p><ul><li><strong>Election Safety:</strong> 在给定term内只能选出一个leader</li><li><strong>Leader Append-Only</strong>: leader永远不覆盖或删除日志，只会添加</li><li><strong>Log Matching</strong>: 如果两个日志在包含相同的index以及term，那么就认定它们完全相同</li><li><strong>Leader Completeness</strong>: 如果一条日志在给定的term内提交，那么它一定会出现在term更大的leader的日志中</li><li><strong>State Machine Safety:</strong> 如果一个服务器已经将给定索引位置的日志条目应用到状态机之中，则其他所有服务器不会在相同索引处出现不同的日志</li></ul><h3 id=raft-basics>Raft basics<a hidden class=anchor aria-hidden=true href=#raft-basics>¶</a></h3><p>一个 Raft 集群可以包含多个服务器；5是一个典型的数量，它允许系统容忍2次故障(有两台服务宕机)。
在给定的时间中每个服务都处在以下三种状态之一:
<em>leader</em>, <em>follower</em>, <em>candidate</em>。 正常情况下，恰好只有一个leader，所有其他服务器都是 follower。</p><ul><li>follower 是被动的: 它们不会自己发出请求，而只是响应来自 leader 和 candidate 的请求。</li><li>leader 处理所有 client 的请求（如果 client 联系到 follower，则 follower 重定向到 leader)。</li><li>candidate 用于选举出一个新的 leader(可以看&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-4>图4</a>
)。</li></ul><h4 id=figure-4>Figure 4<a hidden class=anchor aria-hidden=true href=#figure-4>¶</a></h4><p><figure id=a-/images/9.png class=align-center><img src=/images/9.png alt="Figure 4: Server states。follow 之响应其他服务的请求，如果 follow 没有手段任何通信，就会变成 candidate 并发起选举。获得整个集群
中大多数人投票的 candidate 成为候选人。leader 通常运行到它们失败为止。"><figcaption>Figure 4: Server states。follow 之响应其他服务的请求，如果 follow 没有手段任何通信，就会变成 candidate 并发起选举。获得整个集群
中大多数人投票的 candidate 成为候选人。leader 通常运行到它们失败为止。</figcaption></figure></p><details class="details custom-block"><summary>原文</summary>
A Raft cluster contains several servers; five is a typical number, which allows the system to tolerate two failures.
At any given time each server is in one of three states: leader, follower, or candidate. In normal operation there is
exactly one leader and all of the other servers are followers. Followers are passive: they issue no requests on their
own but simply respond to requests from leaders and candidates. The leader handles all client requests (if a client
contacts a follower, the follower redirects it to the leader). The third state, candidate, is used to elect a new
leader as described in Section 5.2. Figure 4 shows the states and their transitions; the transitions are discussed
below.</details><p>如图5所示: Raft将时间分为任意长度的 <em>terms</em>。terms 的编号是连续的整数。每一个 term 开始于 <em>election</em>，一个或多个 candidate
尝试成为 leader。如果一个 candidate 赢得了选举，那么它将在剩下的 term 内担任 leader。</p><p>在某些特殊情况下选举的结果是 split vote。在这种情况下，term 将会结束并且没有 leader。一个新的 term(伴随新一轮的选举)将很快开始。
Raft保证在给定的 term 内最多只有一个 leader。</p><h4 id=figure-5>Figure 5<a hidden class=anchor aria-hidden=true href=#figure-5>¶</a></h4><p><figure id=a-/images/10.png class=align-center><img src=/images/10.png alt="Figure 5: 将时间划分为 terms，每个 term 都以选举开始。选举成功后，一个 leader管理集群直到 term 结束。在一些选举失败的情况下，
任期结束时都不会选择 leader。可以在不同的服务器上，可以在不同的时间观察到 term 之间的过渡情况。"><figcaption>Figure 5: 将时间划分为 terms，每个 term 都以选举开始。选举成功后，一个 leader管理集群直到 term 结束。在一些选举失败的情况下，
任期结束时都不会选择 leader。可以在不同的服务器上，可以在不同的时间观察到 term 之间的过渡情况。</figcaption></figure></p><details class="details custom-block"><summary>原文</summary>
Raft divides time into terms of arbitrary length, as shown in Figure 5. Terms are numbered with consecutive integers.
Each term begins with an election, in which one or more candidates attempt to become leader as described in Section
5.2. If a candidate wins the election, then it serves as leader for the rest of the term.
In some situations an election will result in a split vote.
In this case the term will end with no leader; a new term (with a new election) will begin
shortly. Raft ensures that there is at most one leader in a given term.</details><p>不同的服务器可能会在不同的时间观察到 terms 之间的转换，在某些情况下，一个服务器可能不会观察到选举甚至整个 terms。
terms 在 Raft 中充当了逻辑时钟， 它们允许服务器检测过时的信息，如过时的 leader。</p><p>每个服务器都存储一个当前的 term 编号，该编号随时间单调地增加。每当服务器进行通信时，就会交换当前 term；
如果一个服务器的当前 term 比另一个服务器的小，那么它就会将其当前 term 更新为较大的值。</p><p>如果一个 candidate 或 leader 发现它的 term 已经过时，它将立即恢复到 follower 的状态。</p><p>如果一个服务器收到的请求是一个过时的 term 编号，它将拒绝该请求。</p><details class="details custom-block"><summary>原文</summary>
Different servers may observe the transitions between terms at different times, and in some situations a server may
not observe an election or even entire terms. Terms act as a logical clock [14] in Raft, and they allow servers to
detect obsolete information such as stale leaders. Each server stores a current term number, which increases
monotonically over time. Current terms are exchanged whenever servers communicate; if one server’s current term is
smaller than the other’s, then it updates its current term to the larger value. If a candidate or leader discovers
that its term is out of date, it immediately reverts to follower state. If a server receives a request with a stale term
number, it rejects the request.</details><p>Raft 服务器使用 RPC 进行通信，而基本的共识算法只需要两种类型的RPC。<code>RequestVote RPCs</code> 由 candidate 在选举期间发起；
<code>AppendEntries RPCs</code>由 leader 发起，用于复制日志条目并提供一种心跳形式。在下面的章节还增加了第三个RPC，用于在服务器之间传输快照。
如果服务器没有及时收到响应，它们会重试 RPC，并且为了获得最佳性能，它们会并行地发出 RPC。</p><details class="details custom-block"><summary>原文</summary>
Raft servers communicate using remote procedure calls (RPCs), and the basic consensus algorithm requires only two
types of RPCs. RequestVote RPCs are initiated by candidates during elections (Section 5.2), and AppendEntries RPCs are
initiated by leaders to replicate log entries and to provide a form of heartbeat (Section 5.3). Section 7 adds a third
RPC for transferring snapshots between servers. Servers retry RPCs if they do not receive a response in a timely
manner, and they issue RPCs in parallel for best performance.</details><h3 id=leader-election>Leader election<a hidden class=anchor aria-hidden=true href=#leader-election>¶</a></h3><p>Raft 使用心跳机制来触发 leader 选举。当服务器启动时，初始状态都是 follower 。只要服务器收到来自 leader 或 candidate 的有效RPC，
它就一直处于 follower 状态。 leader 定期向所有 follower 发送心跳（<code>AppendEntries RPCs</code>，不携带日志条目），以保持他们的权威。
如果 follower 在一段时间内没有收到任何通信(<em>election timeout</em>)，那么它就认为没有可行的 leader ，
并开始选举以选择一个新的 leader。</p><details class="details custom-block"><summary>原文</summary>
Raft uses a heartbeat mechanism to trigger leader election. When servers start up, they begin as followers. A server
remains in follower state as long as it receives validRPCs from a leader or candidate. Leaders send periodic
heartbeats (AppendEntries RPCs that carry no log entries) to all followers in order to maintain their authority. If a
follower receives no communication over a period of time called the election timeout, then it assumes there is no
viable
leader and begins an election to choose a new leader.</details><p>为了开始选举，follower 增加它的当前 term 并过转换到 candidate 状态。
然后，它为自己投票，并行的向集群中的每个其他服务器发出<code>RequestVote RPCs</code>。
candidate 将一直处于这种状态，直到发生以下三种情况之一:</p><ol><li>它赢得了选举</li><li>另一个服务器确立了自己的领导地位</li><li>一段时间内没有赢家。</li></ol><p>接下来就对这些结果进行讨论:</p><details class="details custom-block"><summary>原文</summary>
To begin an election, a follower increments its current term and transitions to candidate state. It then votes for
itself and issues RequestVote RPCs in parallel to each of the other servers in the cluster. A candidate continues in
this state until one of three things happens: (a) it wins the election, (b) another server establishes itself as leader,
or (c) a period of time goes by with no winner. These outcomes are discussed separately in the paragraphs below</details><blockquote><p>它赢得了选举</p></blockquote><p>如果一个 candidate 在同一任期( term )内获得了整个集群中大多数服务器的投票，那么它就赢得了选举。
每台服务器在给定的 term 内最多为一名 candidate 投票，以先来后到为原则。</p><p>少数服从多数的原则保证了最多只有一名 candidate能够在某一 term 内赢得选举
(&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-3>图3</a>
中的选举 Safety 属性)。
一旦一个 candidate 在选举中获胜，它就成为 leader。然后，它向所有其他服务器发送心跳信息(不携带日志的<code>AppendEntries RPC</code>)，
以建立其权威并防止新的选举。</p><details class="details custom-block"><summary>原文</summary>
A candidate wins an election if it receives votes from a majority of the servers in the full cluster for the same term.
Each server will vote for at most one candidate in a given term, on a first-come-first-served basis (note: Section 5.4
adds an additional restriction on votes). The majority rule ensures that at most one candidate can win the election for
a particular term (the Election Safety Property in Figure 3). Once a candidate wins an election, it becomes leader. It
then sends heartbeat messages to all of the other servers to establish its authority and prevent new elections.</details><blockquote><p>另一个服务器确立了自己的领导地位</p></blockquote><p>在等待投票的过程中，candidate 可能会收到另一个服务器的<code>AppendEntries RPC</code>，声称自己是领导者。
如果这个 leader 的term(会携带在 RPC 中)至少与 candidate 的当前 term 一样大，
那么 candidate 就会承认 leader 是合法的并返回到 follower 状态。
如果 RPC 中的 term 比 candidate 当前的 term 小，那么候选者拒绝 RPC，继续处于 candidate 状态。</p><details class="details custom-block"><summary>原文</summary>
While waiting for votes, a candidate may receive an AppendEntries RPC from another server claiming to be leader. If the
leader’s term (included in its RPC) is at least as large as the candidate’s current term, then the candidate recognizes
the leader as legitimate and returns to follower state. If the term in the RPC is smaller than the candidate’s current
term, then the candidate rejects the RPC and continues in candidate state.</details><blockquote><p>一段时间内没有赢家</p></blockquote><p>第三个可能的结果是，一个候选人既没有赢得选举，也没有输掉选举: 如果许多 follower 同时成为 candidate，票数可能被分割，
因此没有 candidate 获得足够的投票。
当这种情况发生时，每个 candidate 都会超时，并通过增加其 term 和启动新一轮的<code>RequestVote RPC</code>来开始新的选举。
然而，如果没有额外的措施，<code>split vote</code> 可能会无限期地重复。</p><details class="details custom-block"><summary>原文</summary>
The third possible outcome is that a candidate neither wins nor loses the election: if many followers become candidates
at the same time, votes could be split so that no candidate obtains a majority. When this happens, each candidate will
time out and start a new election by incrementing its term and initiating another round of RequestVote RPCs. However,
without extra measures split votes could repeat indefinitely.</details><p>Raft使用随机的选举超时时间，以确保 split vote 很少发生，并能迅速解决。为了从一开始就防止 split vote，
选举超时时间是从一个固定的时间间隔中随机选择的(例如150-300ms)。这样每个服务器的选举超时时间就不同了，所以在大多数情况下，只有一个服务器会超时。</p><p>如果一个服务赢得了选举，就在其他服务超时之前发送心跳，split vote 也使用同样的机制来处理。
每个候选人在选举开始时重新启动其随机选举超时(重新计时？)，并等待超时过后再开始下一次选举；这减少了在新的选举中再次出现分裂票的可能性。</p><details class="details custom-block"><summary>原文</summary>
Raft uses randomized election timeouts to ensure that split votes are rare and that they are resolved quickly. To
prevent split votes in the first place, election timeouts are chosen randomly from a fixed interval (e.g., 150–300ms).
This spreads out the servers so that in most cases only a single server will time out; it wins the election and sends
heartbeats before any other servers time out. The same mechanism is used to handle split votes. Each candidate restarts
its randomized election timeout at the start of an election, and it waits for that timeout to elapse before starting the
next election; this reduces the likelihood of another split vote in the new election. Section 9.3 shows that this
approach elects a leader rapidly</details><p>选举是一个用于说明可理解性是如何指导我们在设计方案做权衡的例子。
最初我们计划使用一个排名系统: 每个 candidate 被分配一个唯一的排名，
用来在竞争的 candidate 之间进行选择。如果一个候选人发现了另一个排名更高的候选人，
它就会回到 follower 的状态，这样排名更高的候选人就能更容易地赢得下一次选举。
我们发现这种方法在可用性方面产生了一些微妙的问题(如果一个排名较高的服务失败了，一个排名较低的服务器可能需超时并再次成为
candidate ，但如果它过早地这样做，它可能会重置选举 leader 的进展)。我们对算法进行了多次调整，但每次调整后都会出现新的角落案例。
最终我们得出结论，随机重试的方法更明显，更容易理解。</p><details class="details custom-block"><summary>原文</summary>
Elections are an example of how understandability guided our choice between design alternatives.
Initially we planned to use a ranking system: each candidate was assigned a unique rank,
which was used to select between competing candidates. If a candidate discovered another candidate with higher rank,
it would return to follower state so that the higher ranking candidate could more easily win the next election.
We found that this approach created subtle issues around availability (a lower-ranked server might need to time out and
become a candidate again if a higher-ranked server fails, but if it does so too soon, it can reset progress towards
electing a leader). We made adjustments to the algorithm several times, but after each adjustment new corner cases
appeared. Eventually we concluded that the randomized retry approach is more obvious and understandable.</details><h3 id=log-replication>Log replication<a hidden class=anchor aria-hidden=true href=#log-replication>¶</a></h3><p>一旦一个领导者被选出，它就开始为 client 的请求提供服务。每个 client request 都包含一个要由复制的状态机执行的 command。
leader 将该 command 作为一个新的条目附加到它的日志中，然后并行地将<code>AppendEntries RPCs</code>发送给其他每个服务器以复制该条目。
当条目被安全复制后(如下所述)，leader 将条目应用于其状态机，并将执行结果返回给 client 。
如果 follower 崩溃或运行缓慢，或者网络数据包丢失，领导者会无限期地重试<code>AppendEntries RPCs</code>(甚至在它回应了客户端之后)，
直到所有 follower 最终存储所有日志条目。</p><details class="details custom-block"><summary>原文</summary>
Once a leader has been elected, it begins servicing client requests. Each client request contains a command to be
executed by the replicated state machines. The leader appends the command to its log as a new entry, then is- sues
AppendEntries RPCs in parallel to each of the other servers to replicate the entry. When the entry has been safely
replicated (as described below), the leader applies the entry to its state machine and returns the result of that
execution to the client. If followers crash or run slowly, or if network packets are lost, the leader retries Append-
Entries RPCs indefinitely (even after it has responded to the client) until all followers eventually store all log en-
tries.</details><p><figure id=a-/images/f6.png class=align-center><img src=/images/f6.png alt="Figure 6: 日志是由条目组成的，这些条目按顺序编号。每个条目都包含创建它的 term(每个框中的数字)和状态机的命令。如果一个条目可以安全地应用于状态机，那么该条目就被认为是 committed 的"><figcaption>Figure 6: 日志是由条目组成的，这些条目按顺序编号。每个条目都包含创建它的 term(每个框中的数字)和状态机的命令。如果一个条目可以安全地应用于状态机，那么该条目就被认为是 committed 的</figcaption></figure></p><p>日志的组织方式如&nbsp;<a href=/posts/2022-10-10-raftkv/#a-/images/f6.png>图6</a>
所示。每个日志条目都存储了一个状态机命令，
以及 leader 收到该条目时的 term 编号。日志条目中的 term 编号被用来检测日志之间的不一致，
并确保&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-3>图3</a>
中的一些属性。每个日志条目也有一个整数的索引来标识它在日志中的位置。</p><details class="details custom-block"><summary>原文</summary>
Logs are organized as shown in Figure 6. Each log entry stores a state machine command along with the term number when
the entry was received by the leader. The term numbers in log entries are used to detect inconsistencies between logs
and to ensure some of the properties in Figure 3. Each log entry also has an integer index identifying its position in
the log.</details><p>leader 决定何时将日志条目应用于状态机是安全的,这样的条目被称为 <em>committed</em> 。
Raft 保证所提交的条目是持久的，最终会被所有可用的状态机执行。一旦创建该条目的 leader 将其复制到大多数服务器上，
该日志条目就会被提交(例如，图6中的条目7)。这也会提交 leader 日志中所有之前的条目，包括之前领导者创建的条目。
第5.4节讨论了在 leader 变更后应用这一规则时的一些微妙之处，它还表明这种承诺的定义是安全的。
leader 会跟踪它所知道的已承诺的最高索引，并且它在未来的<code>AppendEntries RPC</code>(包括心跳)中包括该索引，以便其他服务器最终发现。
一旦 follower 得知一个日志条目被提交，它就会将该条目应用于其本地状态机(按日志顺序)。</p><details class="details custom-block"><summary>原文</summary>
The leader decides when it is safe to apply a log entry to the state machines; such an entry is called committed.
Raft guarantees that committed entries are durable and will eventually be executed by all of the available state
machines. A log entry is committed once the leader that created the entry has replicated it on a majority of the
servers (e.g., entry 7 in Figure 6). This also commits all preceding entries in the leader’s log, including entries
created by previous leaders. Section 5.4 discusses some subtleties when applying this rule after leader changes, and it
also shows that this definition of commitment is safe. The leader keeps track of the highest index it knows to be
committed, and it includes that index in future AppendEntries RPCs (including heartbeats) so that the other servers
eventually find out. Once a follower learns that a log entry is committed, it applies the entry to its local state
machine (in log order)</details><p>我们设计的 Raft 日志机制在不同服务器上的日志之间保持高度的一致性。这不仅简化了系统的行为，使其更具可预测性，而且是确保安全的重要组成部分。
Raft 维护了以下特性，它们共同构成了&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-3>图3</a>
中的 Log Matching 特性:</p><blockquote><p>如果不同的两个日志具有相同的 index 以及 term</p></blockquote><ul><li>那么就认为它们存储的是同一个 command</li><li>那么就认为它们之前的所有日志也是相同的</li></ul><details class="details custom-block"><summary>原文</summary><p>We designed the Raft log mechanism to maintain a high level of coherency between the logs on different servers. Not only
does this simplify the system’s behavior and make it more predictable, but it is an important component of ensuring
safety. Raft maintains the following properties, which together constitute the Log Matching Property in Figure 3:</p><ul><li>If two entries in different logs have the same index
and term, then they store the same command.</li><li>If two entries in different logs have the same index
and term, then the logs are identical in all preceding
entries</li></ul></details><p>第一个属性来自于这样一个事实，即一个 leader 在一个给定的 term 中最多创建一个具有给定的日志 index 的条目，
并且日志条目永远不会改变它们在日志中的位置。
第二个属性由<code>AppendEntries</code>执行的简单一致性检查来保证。当发送<code>AppendEntries RPC</code>时，
leader 会包含其日志中紧接新条目之前的条目的 index 和 term 。
如果 follower 在其日志中没有找到具有相同 index 和 term 的条目，那么它将拒绝新条目。
一致性检查作为一个归纳步骤: 日志的初始空状态满足了 Log Matching 属性，并且每当日志被扩展时，一致性检查都会保留 Log
Matching 属性。
因此，每当<code>AppendEntries</code>成功返回时，leader 知道 follower 的日志与自己的日志在新条目之前是相同的</p><details class="details custom-block"><summary>原文</summary>
The first property follows from the fact that a leader creates at most one entry with a given log index in a given term,
and log entries never change their position in the log.
The second property is guaranteed by a simple consistency check performed by AppendEntries.
When sending an AppendEntries RPC, the leader includes the index and term of the
entry in its log that immediately precedes the new entries. If the follower does not find an entry in its log with the
same index and term, then it refuses the new entries. The consistency check acts as an induction step: the initial empty
state of the logs satisfies the Log Matching Property, and the consistency check preserves the Log Matching Property
whenever logs are extended. As a result, whenever AppendEntries returns successfully, the leader knows that the
follower’s log is identical to its own log up through the new entries</details><p>在正常运行期间，leader 和 follower 的日志保持一致，所以<code>AppendEntries</code>一致性检查不会失败。
然而，leader 崩溃会使日志不一致(old leader 可能没有完全复制其日志中的所有条目)。
这些不一致会在一系列 leader 和 follower 的崩溃中加剧。图7说明了 follower 的日志可能与new leader 的日志不同的方式。</p><ul><li>follower 可能会丢失 leader 的条目</li><li>follower 可能会有 leader 没有的额外条目</li><li>或者两者都有</li></ul><p>日志中缺失和多余的条目可能跨越多个 term 。</p><p><figure id=a-/images/f7.png class=align-center><img src=/images/f7.png alt="Figure 7: 当顶端的 leader 掌权时，在 follower 的日志中可能会出现(a-f)中的任何一种情况。
每个盒子代表一个日志条目；盒子里的数字是其 term 。 一个 follower 可能缺少条目(a-b)，可能有额外的未承诺的条目(c-d)，或者两者都有(e-f)。
例如，如果该服务器是第2期的 leader ，在其日志中增加了几个条目，然后在提交任何条目之前就崩溃了；它很快重新启动，成为第3期的 leader，
并在其日志中增加了几个条目；在第2期或第3期的任何条目被提交之前，该服务器又崩溃了，并持续了几个任期。"><figcaption>Figure 7: 当顶端的 leader 掌权时，在 follower 的日志中可能会出现(a-f)中的任何一种情况。
每个盒子代表一个日志条目；盒子里的数字是其 term 。 一个 follower 可能缺少条目(a-b)，可能有额外的未承诺的条目(c-d)，或者两者都有(e-f)。
例如，如果该服务器是第2期的 leader ，在其日志中增加了几个条目，然后在提交任何条目之前就崩溃了；它很快重新启动，成为第3期的 leader，
并在其日志中增加了几个条目；在第2期或第3期的任何条目被提交之前，该服务器又崩溃了，并持续了几个任期。</figcaption></figure></p><details class="details custom-block"><summary>原文</summary>
During normal operation, the logs of the leader and followers stay consistent, so the AppendEntries consistency check
never fails. However, leader crashes can leave the logs inconsistent (the old leader may not have fully replicated all
of the entries in its log). These inconsistencies can compound over a series of leader and follower crashes. Figure 7
illustrates the ways in which followers’ logs may differ from that of a new leader. A follower may be missing entries
that are present on the leader, it may have extra entries that are not present on the leader, or both. Missing and
extraneous entries in a log may span multiple terms.</details><p>在 Raft 中，leader 通过强迫 follower 的日志重复自己的日志来处理不一致的情况。这意味着 follower 日志中的冲突条目将被 leader
日志中的条目覆盖。在下一节将表明，如果再加上一个限制，这就是安全的。</p><details class="details custom-block"><summary>原文</summary>
In Raft, the leader handles inconsistencies by forcing the followers’ logs to duplicate its own. This means that
conflicting entries in follower logs will be overwritten with entries from the leader’s log. Section 5.4 will show that
this is safe when coupled with one more restriction.</details><p>为了使 follower 的日志与自己的日志保持一致，leader 必须找到两个日志一致的最新日志条目，删除该点之后 follower 日志中的所有条目，
并将该点之后的所有 leader 条目发送给 follower。所有这些操作都是为了响应<code>AppendEntries RPC</code>执行的一致性检查而发生的。
leader 为每个 follower 维护一个 nextIndex ，这是 leader 将发送给该 follower 的下一个日志条目的 index 。
当 leader 首次上台时，它会将所有 nextIndex 值初始化为其日志中最后一个值之后的索引(图 7 中的 11)。
如果 follower 的日志与 leader 的日志不一致，则<code>AppendEntries</code>一致性检查将在下一个<code>AppendEntries RPC</code>中失败。
拒绝后，leader 减少 nextIndex 并重试<code>AppendEntries RPC</code>。最终<code>nextIndex</code>将达到 leader 和 follower 日志匹配的点。
发生这种情况时，<code>AppendEntries</code>将成功，这将删除 follower 日志中的任何冲突条目，并从 leader 日志中添加条目(如果有)。
一旦<code>AppendEntries</code>成功，follower 的 log 就会和 leader 的一致，并且在接下来的任期内保持这种状态。</p><details class="details custom-block"><summary>原文</summary>
To bring a follower’s log into consistency with its own, the leader must find the latest log entry where the two logs
agree, delete any entries in the follower’s log after that point, and send the follower all of the leader’s entries
after that point. All of these actions happen in response to the consistency check performed by AppendEntries RPCs. The
leader maintains a nextIndex for each follower, which is the index of the next log entry the leader will send to that
follower. When a leader first comes to power, it initializes all nextIndex values to the index just after the last one
in its log (11 in Figure 7). If a follower’s log is inconsistent with the leader’s, the AppendEntries consis- tency
check will fail in the next AppendEntries RPC. Af- ter a rejection, the leader decrements nextIndex and retries the
AppendEntries RPC. Eventually nextIndex will reach a point where the leader and follower logs match. When this happens,
AppendEntries will succeed, which removes any conflicting entries in the follower’s log and appends entries from the
leader’s log (if any). Once AppendEntries succeeds, the follower’s log is consistent with the leader’s, and it will
remain that way for the rest of the term</details><blockquote><p>如果需要，可以优化协议以减少被拒绝的<code>AppendEntries RPC</code>的数量。例如，当拒绝<code>AppendEntries</code>请求时，
follower 可以包含冲突条目的 term 以它在 term 中存储的第一个索引。
有了这些信息，leader 可以减少 nextIndex 以绕过该 term 中的所有冲突条目；
每个有日志冲突的 term 都只需要一个<code>AppendEntries RPC</code>，而不是每个日志条目一个 RPC。
在实践中，我们怀疑这种优化是否必要，因为失败很少发生，而且不太可能有很多不一致的条目。</p></blockquote><details class="details custom-block"><summary>原文</summary>
If desired, the protocol can be optimized to reduce the number of rejected AppendEntries RPCs. For example, when
rejecting an AppendEntries request, the follower can include the term of the conflicting entry and the first index it
stores for that term. With this information, the leader can decrement nextIndex to bypass all of the conflicting
entries in that term; one AppendEntries RPC will be required for each term with conflicting entries, rather than one RPC
per entry. In practice, we doubt this optimization is necessary, since failures happen infrequently and it is unlikely
that there will be many inconsistent en- tries</details><p>通过这种机制，leader 在上台时无需采取任何特殊措施来恢复日志一致性。它刚刚开始正常运行，
并且日志会自动收敛以响应<code>AppendEntries</code>一致性检查的失败。
leader 永远不会覆盖或删除自己日志中的条目(&nbsp;<a href=/posts/2022-10-10-raftkv/#figure-3>图3</a>
中的 Leader Append-Only )。</p><details class="details custom-block"><summary>原文</summary>
With this mechanism, a leader does not need to take any special actions to restore log consistency when it comes to
power. It just begins normal operation, and the logs automatically converge in response to failures of the Append-
Entries consistency check. A leader never overwrites or deletes entries in its own log (the Leader Append-Only Property
in Figure 3).</details><p>理想的 Raft:</p><ul><li>只要大多数服务器启动，Raft 就可以接受、复制和应用新的日志条目</li><li>可以通过单轮 RPC 将新条目复制到集群的大部分；</li><li>并且单个慢速 follower 不会影响性能。</li></ul><details class="details custom-block"><summary>原文</summary>
This log replication mechanism exhibits the desirable consensus properties described in Section 2: Raft can ac- cept,
replicate, and apply new log entries as long as a ma- jority of the servers are up; in the normal case a new entry can
be replicated with a single round of RPCs to a ma- jority of the cluster; and a single slow follower will not impact
performance.</details><h3 id=safety>Safety<a hidden class=anchor aria-hidden=true href=#safety>¶</a></h3><h1 id=代码实现思路>代码实现思路<a hidden class=anchor aria-hidden=true href=#代码实现思路>¶</a></h1><h2 id=2a-1>2A<a hidden class=anchor aria-hidden=true href=#2a-1>¶</a></h2><ol><li>根据图2中的 state 这一节添加对应的属性</li><li>添加<code>RaftRole</code>属性，代表当前的角色: leader，candidate，follower</li><li>实现<code>ticker</code>这个函数:<ul><li>判断是否很久没有收到心跳，来发起选举</li><li>判断是否需要发送心跳，来维持自己的权威</li></ul></li></ol><h1 id=links>Links<a hidden class=anchor aria-hidden=true href=#links>¶</a></h1><ol><li>项目地址: &nbsp;<a href=https://pdos.csail.mit.edu/6.824/labs/lab-raft.html target=_blank rel=noopener>https://pdos.csail.mit.edu/6.824/labs/lab-raft.html</a></li><li>GFS 相关资料: &nbsp;<a href=https://fzdwx.github.io/posts/2022-10-07-gfs/#links target=_blank rel=noopener>https://fzdwx.github.io/posts/2022-10-07-gfs/#links</a></li><li>Raft paper: &nbsp;<a href=https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf target=_blank rel=noopener>https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf</a></li><li>Diagram of Raft interactions： &nbsp;<a href=https://pdos.csail.mit.edu/6.824/notes/raft_diagram.pdf target=_blank rel=noopener>https://pdos.csail.mit.edu/6.824/notes/raft_diagram.pdf</a></li><li>Students guid to Raft: &nbsp;<a href=https://thesquareplanet.com/blog/students-guide-to-raft/ target=_blank rel=noopener>https://thesquareplanet.com/blog/students-guide-to-raft/</a></li><li>Raft locking: &nbsp;<a href=https://pdos.csail.mit.edu/6.824/labs/raft-locking.txt target=_blank rel=noopener>https://pdos.csail.mit.edu/6.824/labs/raft-locking.txt</a></li><li>Raft structure: &nbsp;<a href=https://pdos.csail.mit.edu/6.824/labs/raft-structure.txt target=_blank rel=noopener>https://pdos.csail.mit.edu/6.824/labs/raft-structure.txt</a></li><li>Paxos Replicated State Machines as the Basis of a High-Performance Data
Store &nbsp;<a href=https://static.usenix.org/event/nsdi11/tech/full_papers/Bolosky.pdf target=_blank rel=noopener>https://static.usenix.org/event/nsdi11/tech/full_papers/Bolosky.pdf</a></li><li>TiKV 对于 Raft 优化 &nbsp;<a href=https://cn.pingcap.com/blog/optimizing-raft-in-tikv target=_blank rel=noopener>https://cn.pingcap.com/blog/optimizing-raft-in-tikv</a></li><li>&nbsp;<a href=https://www.cnblogs.com/niejunlei/p/9719557.html target=_blank rel=noopener>https://www.cnblogs.com/niejunlei/p/9719557.html</a></li><li>&nbsp;<a href=https://blog.csdn.net/viskaz/article/details/124232474 target=_blank rel=noopener>https://blog.csdn.net/viskaz/article/details/124232474</a></li><li>&nbsp;<a href=https://www.cnblogs.com/brianleelxt/p/13251540.html target=_blank rel=noopener>https://www.cnblogs.com/brianleelxt/p/13251540.html</a></li></ol></div></article></main><footer class=footer><span>Copyright &nbsp;<a href=https://github.com/fzdwx target=_blank rel=noopener>fzdwx</a>
since 2022</span></span>
<span><a target=_blank href=https://github.com/fzdwx/fzdwx.github.io/issues>欢迎交流</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>(function(){const t=""=="1";if(t)return;let e=document.getElementById("theme-toggle");e.removeEventListener("click",toggleThemeListener),e.addEventListener("click",toggleThemeListener)})()</script><script>(function(){let e=document.getElementById("menu");e&&(e.scrollLeft=localStorage.getItem("menu-scroll-position"),e.onscroll=function(){localStorage.setItem("menu-scroll-position",e.scrollLeft)});const t=""=="1",n="1"=="1";if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||t||n)return;document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})})()</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>if(window.scrollListeners)for(const e of scrollListeners)window.removeEventListener("scroll",e);window.scrollListeners=[]</script><script src=/js/medium-zoom.min.js data-no-instant></script>
<script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){const a="1"=="1";if(!a)return;if(!document.querySelector(".toc")){console.log("no toc found, ignore toc scroll");return}const r=window.scrollListeners,t=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id]"),n="active";let e=t[0];o(e).classList.add(n);const c=()=>{const s=[];for(const e of t)if(l(e)<5)s.push(e);else break;s.length>0?newActiveHeading=s[s.length-1]:newActiveHeading=t[0],e!=newActiveHeading&&(o(e).classList.remove(n),e=newActiveHeading,o(e).classList.add(n))};let s=null;const i=()=>{s!==null&&clearTimeout(s),s=setTimeout(c,50)};window.addEventListener("scroll",i,!1),r.push(i);function o(e){const t=encodeURI(e.getAttribute("id")).toLowerCase();return document.querySelector(`.toc ul li a[href="#${t}"]`)}function l(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect();return t.top}})()</script><script>mediumZoom(".entry-cover img"),mediumZoom(".post-content img:not([no-zoom])")</script><script src=/js/instantclick.min.js data-no-instant></script>
<script data-no-instant>InstantClick.init()</script><script src=https://unpkg.com/lucide@latest></script>
<script>lucide.createIcons()</script></body></html>